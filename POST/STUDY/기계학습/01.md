---
title: Lec1 The Machine Learning Landscape
data: 2025-09-01
---

## What Is Machine Learning?

  * 데이터로부터 학습하도록 컴퓨터를 프로그래밍하는 과학
    
  * Arthur Samuel (1959) :
    
    * 명시적으로 프로그래밍하지 않고도 컴퓨터에게 학습 능력을 부여하는 분야
      
  * Tom Mitchell (1997) :
    
    * 작업 T와 성능측정 P에 대해, 경험 E로부터 학습해 T에서의 성능(P로 측정)이 E와 함께 향상되면 그 프로그램은 학습했다고 한다.

  * 스팸 필터 예시

    * 사용자에 의해 표시된 스팸/정상(햄) 이메일 예시를 학습하여 스팸을 식별
    * 학습에 쓰이는 예시 집합: 학습 데이터셋 (training set)
    * 각 예시: 학습 인스턴스/샘플 (training instance/sample)
    * 작업 T: 새 이메일의 스팸 판별, 경험 E: 학습 데이터, 성능 P: 예를 들어 정확도 (Accuracy)
      
  * 단순히 위키피디아를 내려받는 것은 데이터가 늘어날 뿐, 어떤 작업 성능도 향상시키지 않으므로 머신러닝이 아님

---

## Why Use Machine Learning?

  * 전통적 프로그래밍으로 스팸 필터를 만든다면:

    1. “4U”, “credit card”, “free”, “amazing” 등의 패턴을 발견
    2. 각 패턴에 대한 탐지 알고리즘을 작성하고, 다수 탐지 시 스팸으로 표시
    3. 테스트와 반복
       
  * 현실적으로 규칙 목록이 길고 복잡해져 유지보수가 어려움

  * 머신러닝 기반 스팸 필터는 스팸/햄에서 단어의 비정상적 빈도를 비교하여 예측에 유용한 단어/구를 자동 학습
  * 프로그램은 더 짧고, 유지보수 용이하며, 대개 더 정확함

  * 적응성 (Adaptation)

    * 스패머가 “4U” 대신 “For U”로 우회하면

      * 전통적 방식: 새 규칙 추가 필요 (끝없는 규칙 보완)
      * 머신러닝: 사용자 플래그 기반으로 “For U”의 비정상적 빈도를 자동 감지하여 규칙 추가 없이 대응

  * 전통 방법이 지나치게 복잡하거나 알려진 알고리즘이 없는 문제에 강점

    * 예: 음성 인식 (Speech Recognition)

      * “one”과 “two”만 구분하는 규칙은 가능하더라도, 수천 단어·수백만 화자·소음·다국어 상황에는 확장 불가
      * 다수의 예제 녹음을 통해 스스로 학습하는 접근이 최선


* 머신러닝은 사람이 배우는 데에도 도움을 줍니다.

  * ML 알고리즘이 무엇을 학습했는지 점검할 수 있습니다(일부 알고리즘은 어려울 수 있음).
  * 예: 스팸 필터가 충분한 스팸으로 학습된 후, 스팸 예측에 가장 효과적인 단어/단어 조합 목록을 확인할 수 있습니다.
  * 이를 통해 예상치 못한 상관관계나 새로운 추세를 발견하여 문제를 더 잘 이해하게 됩니다.
* 대량 데이터에 ML 기법을 적용하면 즉시 드러나지 않았던 패턴을 발견할 수 있습니다.

  * 이를 데이터 마이닝 (Data Mining)이라 합니다. 

* 요약하면, 머신러닝이 특히 유용한 경우:

  * 기성 해법이 미세 조정이나 긴 규칙 목록을 요구하는 문제: 하나의 ML 알고리즘이 코드를 단순화하고 전통적 방법보다 더 잘 작동할 수 있습니다.
  * 전통적 접근으로는 좋은 해법이 없는 복잡한 문제: 최적의 ML 기법이 해법을 찾을 수도 있습니다.
  * 변동하는 환경: ML 시스템은 새로운 데이터에 적응할 수 있습니다.
  * 복잡한 문제와 대규모 데이터에 대한 통찰을 얻는 경우. 

---

## Examples of Applications

  * 생산 라인 제품 이미지 자동 분류
  * 뇌 스캔에서 종양 탐지
  * 뉴스 기사 자동 분류
  * 포럼의 공격적 댓글 자동 플래그
  * 장문 문서 자동 요약
  * 챗봇/개인 비서 생성
  * 다양한 성과 지표를 바탕으로 내년 매출 예측
  * 음성 명령 반응 앱
  * 신용카드 사기 탐지
  * 구매 이력 기반 고객 세분화 및 세그먼트별 마케팅
  * 고차원 데이터를 명확·통찰적으로 표현하는 도식화
  * 과거 구매 기반 제품 추천
  * 게임용 지능형 봇 구축 

---

## Types of Machine Learning Systems

  * 감독 여부: 지도학습/비지도학습/준지도학습/강화학습
  * 점증적 학습 가능 여부: 온라인 학습 (Online Learning) vs 배치 학습 (Batch Learning)
  * 유사도 비교 기반인지, 패턴을 학습해 예측 모델을 구축하는지: 사례기반 (Instance-Based) vs 모델기반 (Model-Based) 학습

---

### Supervised/Unsupervised Learning

#### 지도학습 (Supervised Learning)

  * 학습용 데이터셋에 정답(레이블, Labels)이 포함됩니다.
  * 대표 과제: 분류 (Classification) — 스팸 필터는 스팸/햄 레이블이 달린 이메일 예제들로 학습하여 새 이메일을 분류합니다. 

  * 또 다른 대표 과제: 수치 목표값 예측 (회귀, Regression) — 예: 주행거리/연식/브랜드 등 특징(예측변수, Predictors)으로 자동차 가격 예측
  * 학습에는 각 자동차의 예측변수와 정답(가격) 예제가 많이 필요합니다. 

* 본 교과에서 다루는 주요 지도학습 알고리즘

  * k-최근접 이웃 (k-Nearest Neighbors)
  * 선형 회귀 (Linear Regression)
  * 로지스틱 회귀 (Logistic Regression)
  * 서포트 벡터 머신 (Support Vector Machines, SVMs)
  * 결정트리 & 랜덤 포레스트 (Decision Trees, Random Forests)
  * 신경망 (Neural Networks) 


#### 비지도학습 (Unsupervised Learning)

  * 라벨 없는 데이터로 교사 없이 패턴을 학습합니다.
  * 예: 블로그 방문자 데이터를 클러스터링하여 유사 방문자 그룹을 자동 탐색(어느 그룹인지 알려주지 않음). 

  * 시각화 알고리즘: 복잡하고 라벨 없는 데이터를 2D/3D로 투영하여 도식화합니다. 

  * 차원 축소 (Dimensionality Reduction): 정보를 크게 잃지 않으면서 데이터 단순화

    * 상관된 특징을 합쳐 새 특징(특징 추출, Feature Extraction) 생성
    * 예: 주행거리와 연식 → ‘노후도’
  * 이상치 탐지 (Anomaly Detection): 이상 거래/제조 결함 탐지, 다른 알고리즘 학습 전 이상치 제거 등 

  * 연관 규칙 학습 (Association Rule Learning): 속성 간 흥미로운 연관성 탐색

    * 예: 바비큐 소스+포테이토칩 구매 고객이 스테이크도 자주 구매 → 진열 전략에 활용 

* 주요 비지도학습 알고리즘

  * 클러스터링: K-평균 (K-Means), DBSCAN, 계층적 군집 (HCA)
  * 이상/신규성 탐지: 원클래스 SVM, 아이솔레이션 포레스트
  * 시각화/차원 축소: PCA, 커널 PCA, LLE, t-SNE
  * 연관 규칙: Apriori, Eclat 


#### 준지도학습 (Semisupervised Learning)

  * 라벨링 비용 때문에 보통 ‘라벨 없음’이 다수, ‘라벨 있음’이 소수
  * 준지도학습은 부분 라벨 데이터에 대응합니다. 

  * 예: 사진 서비스가 같은 사람을 자동으로 묶어(클러스터링) 놓으면, 각 사람에 라벨을 하나씩만 달아도 모든 사진에 이름을 매길 수 있음
  * 대부분의 준지도 알고리즘은 비지도+지도 알고리즘의 조합입니다. 


#### 강화학습 (Reinforcement Learning)

  * 강화학습은 매우 다릅니다.
  * 에이전트 (Agent)는 환경을 관찰하고, 행동을 선택·수행하며, 그에 따른 보상(Reward)을 받습니다. 

---

### Batch and Online Learning

#### 배치 학습 (Batch Learning)

  * 모든 가용 데이터를 한 번에 사용해 오프라인으로 학습
  * 배포 후에는 더 이상 학습하지 않고 학습 내용을 적용만 함 (오프라인 학습)
  * 새로운 데이터 반영 시 전체 데이터로 처음부터 다시 학습하여 교체 필요 


#### 온라인 학습 (Online Learning)

  * 인스턴스를 순차적으로(개별 또는 미니배치) 공급해 점진적으로 학습
  * 각 학습 단계가 빠르고 저렴하여 도착 즉시 새 데이터에 적응 가능 

  * 주메모리에 안 들어갈 만큼 큰 데이터셋에 대해 ‘코어 외 학습 (Out-of-Core Learning)’ 가능
  * 일부 데이터를 불러와 학습 단계를 수행하고 이를 반복 


  * 나쁜 데이터가 들어오면 성능이 점진적으로 저하될 수 있음
  * 이를 줄이려면 성능 모니터링을 통해 필요 시 학습을 중단/이전 상태로 롤백
  * 입력 데이터 모니터링 및 이상치 탐지 등도 고려 

---

### Instance-Based Vs. Model-Based Learning

* 일반화 방식에 따른 분류

  * 대부분의 ML 과제는 예측이며, 본 적 없는 예시에 대해 잘 작동해야 함
  * 학습 데이터에서의 성능만으로는 부족 — 새 인스턴스에서의 성능이 목표
  * 일반화 접근: 사례기반 학습 (Instance-Based) vs 모델기반 학습 (Model-Based) 


#### 사례기반 학습 (Instance-Based Learning)

  * 알려진 스팸과 **유사한** 이메일도 스팸으로 간주하려면 유사도 측정이 필요
  * 예: 공통 단어 수를 유사도 지표로 사용
  * 예시를 ‘암기’한 뒤, 유사도 비교로 새로운 사례에 일반화하는 방식 


#### 모델기반 학습 (Model-Based Learning)

  * 예시들로부터 **모델**을 구축하고, 그 모델로 예측
  * 이를 모델기반 학습이라 합니다. 

---

## Main Challenges of Machine Learning

### 학습 데이터의 양 부족 (Insufficient Quantity of Training Data)

  * 대부분의 ML 알고리즘은 충분한 데이터가 필요
  * 단순 문제에도 수천 예제가, 이미지/음성 인식 등 복잡 문제엔 수백만 예제가 필요
  * “알고리즘 개선 vs 코퍼스(데이터) 확충”의 트레이드오프 재고 필요 (Banko & Brill, 2001)
  * “데이터의 비상한 효용성 (The Unreasonable Effectiveness of Data)” (Norvig et al., 2009) 에서 데이터의 중요성이 재차 강조됨 


### 대표성 없는 학습 데이터 (Nonrepresentative Training Data)

  * 일반화에는 대표성이 중요
  * 누락된 국가를 추가한 예에서 보듯, 표본이 작으면 표본잡음(sampling noise), 표본추출 방식이 잘못되면 표본편향(sampling bias)이 발생 

* 1936년 미국 대선 사례

  * Literary Digest의 대규모 우편 조사(1,000만 발송, 240만 회수) 결과: Landon 57% 예측
  * 실제: Roosevelt 62% 득표로 당선
  * 표본편향 예:

    * 주소 수집원(전화번호부·잡지구독자·클럽명단 등)이 부유층 편향
    * 응답률 < 25% → 무응답 편향 (Nonresponse Bias) 유발 


### 저품질 데이터 (Poor-Quality Data)

  * 오류·이상치·노이즈가 많으면 패턴 탐지가 어려워 성능 저하
  * 데이터 정제에 시간을 들일 가치가 큼(실무에서 많은 시간 소요)
* 무관한 특징 (Irrelevant Features)

  * “Garbage in, garbage out”
  * 특징 공학 (Feature Engineering):

    * 특징 선택 (Feature Selection)
    * 특징 추출 (Feature Extraction) — 차원 축소 기법 활용 가능
    * 신규 특징 생성(데이터 추가 수집) 


### 과적합 (Overfitting)

  * 사람의 과잉 일반화와 유사한 함정에 빠질 수 있음 

  * 작은/노이즈 많은 데이터에서 복잡 모델(예: 딥러닝)은 노이즈의 패턴까지 학습
  * 해결:

    * 더 단순한 모델(매개변수 수 축소, 차원 축소, 제약 추가)
    * 더 많은 데이터 수집
    * 데이터 노이즈/오류/이상치 제거
  * 정규화 (Regularization): 모델을 제약·단순화해 과적합 위험 완화
  * 하이퍼파라미터 (Hyperparameter): 학습 전 설정·학습 중 고정되는 **학습 알고리즘**의 매개변수로 정규화 강도 등을 제어 


### 과소적합 (Underfitting)

  * 모델이 지나치게 단순하여 데이터의 구조를 학습하지 못하는 경우
  * 해결:

    * 더 강력한 모델 선택(매개변수 증가)
    * 더 나은 특징 제공(특징 공학)
    * 모델 제약 완화(정규화 강도 축소 등) 

---

## Testing and Validating

* 일반화 성능 평가는 새 데이터에서만 확인 가능

  * 배포 후 모니터링은 가능하지만, 성능이 매우 낮으면 사용자 불만
  * 더 나은 방법: 학습/테스트 셋 분리 → 테스트 셋 성능으로 일반화 오차(Generalization Error; Out-of-Sample Error) 추정 


* 트레이닝 에러는 낮지만 일반화 에러가 높다면 과적합
* 관례적 분할: 학습 80% / 테스트 20% (데이터 크기에 따라 가변)

  * 예: 1천만 개면 테스트 1%(=10만)만으로도 충분히 안정된 추정 가능 


* 하이퍼파라미터 튜닝과 모델 선택

  * 단순 비교는 테스트 셋으로 가능
  * 하지만 테스트 셋을 반복 사용해 모델/하이퍼파라미터를 ‘적응’시키면, 실제 배포 성능이 과대평가될 수 있음(테스트 셋 오염) 


* 홀드아웃 검증 (Holdout Validation)

  * 학습 셋 일부를 **검증 셋 (Validation Set)** 으로 분리
  * 다양한 하이퍼파라미터/모델 후보를 학습(축소된 학습 셋) → 검증 셋으로 성능 비교 → 최선 모델을 전체 학습 셋(검증 포함)으로 재학습 → 마지막에 테스트 셋으로 일반화 오차 추정 

* 교차 검증 (Cross-Validation)

  * 검증 셋이 너무 작으면 평가가 부정확, 너무 크면 학습 데이터가 줄어듦
  * 다수의 작은 검증 셋으로 반복 교차 검증 → 평균 성능으로 더 정확한 추정(단, 학습 시간이 검증 셋 수만큼 증가) 

* 데이터 불일치 (Data Mismatch)

  * 학습 데이터는 크지만 배포 환경 데이터와 분포가 다를 수 있음
  * 예: 웹에서 수집한 꽃 사진으로 학습 → 실제 모바일 앱 사진과 미스매치
  * 핵심 규칙: **검증/테스트 셋은 배포 시 사용할 데이터와 최대한 대표성이 같아야 함** 


  * 학습용 웹 이미지를 일부 **Train-Dev 셋**으로 분리해 모델을 평가
  * Train-Dev에서 성능이 좋고 검증 셋에서 나쁘면 **분포 불일치** 문제

    * 웹 이미지를 모바일 사진처럼 전처리 후 재학습 시도
      
  * Train-Dev에서도 나쁘면 **과적합** 가능성 → 모델 단순화/정규화, 데이터 확충/정제 

---

## 요약 (Summary)

  * ML은 규칙을 명시적으로 코딩하지 않고, 데이터로부터 학습하여 특정 작업 성능을 향상시키는 방법입니다.
  * ML 시스템 유형: 감독 여부, 배치/온라인, 사례기반/모델기반 등 다양
  * ML 프로젝트: 학습 셋 수집 → (모델기반이라면) 파라미터를 데이터에 맞춰 조정하여 학습 셋에서 성능을 높이고, 새 사례에도 잘 일반화되길 기대

    * (사례기반이라면) 예시를 암기하고 유사도 측정으로 일반화
  * 성능 저하 요인: 데이터 부족, 대표성 부족, 노이즈/오류/무관 특징(“Garbage in, garbage out”)
  * 모델이 너무 단순하면 과소적합, 너무 복잡하면 과적합이 발생합니다. 
