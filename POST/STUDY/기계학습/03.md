---
title: Lec3 Classification
date: 2025-09-15
---

## 1. MNIST

* MNIST dataset를 사용해보자.
  * 숫자 손글씨 이미지
  * ML 계의 "Hello, World!" 로 불린다
 
* `Scikit-Learn`은 인기있는 dataset을 다운받는 헬퍼 함수를 제공한다.
  ```python
  from sklearn.datasets import fetch_openml
  mnist = fetch_openml('mnist_784', version=1)
  ```
  
* `Scikit-Learn`을 통해 로드된 데이터셋은 비슷한 구조로 정의되어있다.
  ```python
  mnist.keys()
  # dict_keys(['data', 'target', 'feature_names', 'DESCR', 'details', 'categories', 'url'])
  ```

* `X = mnist["data"]`
  * `X.shape()` 7만개의 이미지, 각각 784개의 특징을 가진다.
  * 784개의 특징은 28 x 28 픽셀 각각의 intensity를 말하며, 0-255 값을 가진다.
 
* `X[0].reshape(28,28)`
  * dataset 중 하나를 28 x 28로 reshape하여 직접 확인할 수 있다.
 
* `y = mnist["target"]`
  * target은 각 데이터의 라벨을 담는 배열이다.
  * string 이므로 `y = y.astype(np.uint8)` 형변환 하여 사용한다.
 
* 시작 전 항상 테스트 셋을 빼놔야하는데, MNIST 데이터 셋은 앞의 6만장이 training set, 뒤의 1만장이 test set으로 나누어져있다.

---

## 2. Training a Binary Classifier

* 이미지를 5 또는 not-5, 두 개의 클래스로 구분하는 문제로 단순화해보자. 

* Stochastic Gradient Descent (SGD) 
  * SGD 분류기는 학습 샘플을 한 번에 하나씩 독립적으로 처리한다.
  * 이 때문에 대용량 데이터 셋을 효과적으로 처리할 수 있다.

---

## 3. Performance Measures

### Measuring Accuracy Using Cross-Validation

* `cross_val_score()` 함수를 사용해 SGD 분류 모델을 평가해보면 (K-fold 교차 검증(3-fold) 활용) 모든 폴드에서 93% 이상 정확도가 나온다. 과연 좋은 결과일까?

* 모든 이미지를 not-5 클래스로 분류해버리는 바보 분류기 또한 90% 이상의 정확도가 나온다.

* 이를 통해, 정확도를 성능 지표로 삼는 것이 좋지 않다는 것을 알 수 있다. (특히 불균형한 데이터 셋에서)

### Confusion Matrix

분류기의 성능을 평가하는 더 좋은 방법으로 `confusion matrix` 가 있다.

행렬의 행과 열은 각각 실제 클래스와 예측 클래스를 의미한다

|Actual\Predict|Negative (non 5)|Positive (5)|
|---|---|---|
|Negative (non 5) |True Negatives |False Positives|
|Positive (5)|False Negatives|True Positives|

> 이때, 예측 값을 test set을 통해 받는 행위를 하면 안되기 때문에 `cross_val_predict()`를 사용한다.

완벽한 분류기라면 주대각선(좌상단→우하단)에만 nonzero 값이 나타난다.

positive 정확도를 보는 지표를 precision 이라고 한다.: 맞다고 한게 얼마나 실제로 맞았는지
  
$$
\text{precision}=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FP}}
$$

recall(= sensitivity, True Positive Rate(TPR)) 은 positive 를 제대로 찾아낸 비율을 의미한다.: 실제로 맞는 값을 얼마나 맞다고 했는지

$$
\text{recall}=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}}
$$

### Precision and Recall

`Scikit-Learn` 에서 제공하는 precision 과 recall 반환 함수를 통해 기존의 SGD 분류기를 다시 평가해보면 precision 72.9%, recall 75.6% 가 나온다.

precision 과 recall 의 조화평균을 F1 score 라고 부른다. 조화평균은 산술평균과 달리 작은 값에 더 큰 가중치를 두기때문에 두 값이 모두 높을때 높은 점수를 받을 수 있다.

F1 점수는 precision 과 recall 이 비슷한 것을 좋아하지만, 어떤 상황에서는 precison 이 더 중요하고, 어떤 상황에서는 recall 이 중요할 수 있다.

예를 들어 아동에게 안전한 영상을 걸러내는 분류기를 만든다면, 괜찮은 영상을 많이 거부하더라고 진짜 안전한 것만 남기는 것이 중요하고, 절도범 탐지 분류기를 만든다면 오탐을 하더라도 모든 절도범을 찾을 수 있는게 중요한다.

둘 다 동시에 극대화하기는 어렵다. 하나를 올리면 나머지가 내려간다. 이를 precision/recall trade-off 라고 부른다.

threshold보다 크면 양성, 작으면 음성으로 간주할때, 이 값이 높을수록 precision이 높아지고 recall이 낮아진다.

threshold 를 어떻게 결정할까? `cross_val_predict()` 를 사용해 결정 점수를 얻고, 이를 통해 결정 점수 분포 `precision_recall_curve()` 를 얻어 곡선을 그린 다음 문제 상황에 맞는 임계값을 고르면 된다.

또 다른 방법으로는 정밀도를 재현율에 대해 직접 그래프로 그려보는 것이다.

정밀도 90%를 목표로 하기로 했다고 가정하면, 정밀도가 최소 90% 이상이 되는 가장 낮은 임계값을 찾아 설정하면 된다.

### The ROC Curve

ROC 곡선은 true positive rate (= recall) 을  false positive rate(FPR: 실제 음성 중 잘못 분류된 비율) 에 대해 그래프로 그린 것이다.

TPR 을 높일수록 분류기가 만들어내는 FPR 도 많아집니다.

ROC 곡선의 아래 면적 (AUC, area under curve) 을 비교하면 분류기를 비교할 수 있다. 완벽한 분류기의 ROC AUC는 1이고 (좌상단을 찍고 지나가는 선), 완전히 무작위 분류기의 ROC AUC는 0.5이다(y=x).

일반적으로는 roc 곡선을 사용하고, 양성이 적거나 거짓 양성을 신경 써야할 때는 precisoin/recall 곡선을 쓴다.

---

## 4. Multiclass Classification

원래부터 다중 클래스를 처리하는 알고리즘도 있고, 본질적으로 이진 분류기인 알고리즘도 있다. 후자도 이진 분류기를 여러개 사용하여 다중 클래스 분류를 수행할 수 있다.

OvR(One-Versus-the-Rest) 전략은 예를 들면, 각 숫자별로 이진 분류기 하나씩 학습하고, 가장 높은 점수를 내는 분류기의 클래스를 선택하는 것이다. OvO(One-Versus-One) 전략은 모든 숫자 쌍마다 이진 분류시를 학습 (1 vs 2, 1 vs 3, ...) 하고 가장 많이 승리한 클래스를 선택하는 것이다. 이때 클래스가 N개라면 N×(N−1)/2 개의 분류기가 필요하다. 각 분류기는 자신이 구분해야 하는 두 클래스의 데이터만 학습하면 된다는 것이 장점이다.

`Scikit-Learn`은 이진 분류 알고리즘을 다중 클래스 분류에 사용하려고 하면 자동으로 OvR 또는 OvO 전략을 실행한다.

`decision_function()` 메서드를 호출하면, 각 샘플마다 10개의 점수가 반환되는 것을 볼 수 있습니다. 즉, 클래스 하나당 점수 하나씩입니다.

---

## 5. Error Analysis

confision matrix를 보자. 주대각선 (정답 맞춘 애들)의 값이 웬만하면 높다.

에러를 잘 보이게 하기 위해서 올바른 예측을 제외하고 오류들만 가지고 다시 행렬을 만든다.

개별 오류를 분석하면 분류기가 무엇을 어떻게 하고, 왜 실패하는지를 이해하는 데에 좋다.

어디서 실패가 많이 발생하는지 확인하고, 적절한 전처리를 통해 보정하여 오류를 줄인다면 아주 좋음

---

## 6. Multilabel Classification

하나의 샘플이 여러개의 클래스에 할당되는, multilabel 분류에 대해 알아보자. KNeighborsClassifier은 멀티라벨 분류를 지원한다.

멀티라벨 분류에서는 샘플마다 라벨이 여러 개라서, 성능을 판단할때는 라벨별 f1 스코어의 평균을 낸다.

멀티라벨을 지원하지 않는 분류기를 쓰고싶다면, 라벨마다 별도의 모델을 하나씩 학습하면 되는데, 이 경우 라벨들 사이의 의존성을 포착하기는 어렵다. 이 문제를 해결하기 위해 모델들을 체인 형태로 구성하여, 앞선 모델들의 예측값들도 입력으로 사용하는 방법이 있다.

이때 체인의 앞쪽 순서의 모델일수록 다른 라벨들에 대한 정보가 없기 때문에 순서가 중요한데, 일반적으로 최적 순서를 알 수 없으므로 무작위 순서의 여러 체인을 학습한 뒤 그 예측을 평균내는 방식이 가장 흔하다.

---

## 7. Multioutput Classification

멀티라벨 분류의 일반화로, 각 라벨이 두 개 이상의 값을 가질 수 있는 분류이다. 예로, 이미지 잡음 제거 문제에서의 출력은 픽셀마다 0-255값을 가지는 픽셀 강도 배열로, 멀티라벨이다.

> 분류와 회귀의 경계는 모호할 때가 있다. 이미지 잡음 제거 문제에서 각 픽셀의 강도를 예측하는 작업은 분류보다는 회귀에 가까운 작업이다.


MNIST 이미지에 numpy의 `randint()` 함수로 랜덤 노이즈를 추가하여 학습해보자. 타겟 이미지는 원본 이미지로 둔다.


